{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street View House Numbers - Evaluation on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version : 1.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import svhn\n",
    "import graphics\n",
    "import keras_utils\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "max_digits = 7\n",
    "image_size = (48,116)\n",
    "\n",
    "# print the keras version used\n",
    "import keras\n",
    "print \"Keras version : {}\".format(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test dataset\n",
    "Here we load the sample points as individual prediction targets. We will not flatten the data like we did during training, since we have to predict the complete sequence of digits in an image together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data file (takes time)\n",
    "rawdata = svhn.read_process_h5('../inputs/test/digitStruct.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract resized images, counts and label sequences for each sample\n",
    "def generateTestData(data, n=100):\n",
    "    Ximg = []\n",
    "    ycount = []\n",
    "    ylabel = []\n",
    "    for datapoint in np.random.choice(data, size=n, replace=False):\n",
    "        img,rawsize = svhn.createImageData(datapoint, image_size, '../inputs/test/')\n",
    "        Ximg.append(img)\n",
    "        ycount.append(datapoint['length'])\n",
    "        ylabel.append(datapoint['labels'])\n",
    "        \n",
    "    ylabel = [[0 if y==10 else int(y) for y in ys] for ys in ylabel]\n",
    "    return np.array(Ximg), np.array(ycount), np.array(ylabel)\n",
    "    \n",
    "# change to 13068 to test on full test dataset\n",
    "Ximg, ycount, ylabel = generateTestData(rawdata, 13068)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models\n",
    "Our training graph is composed of macro models - vision, counter and label detector. While it was suitable for training on flattened data, we will need to organize the models differently to generate sequence predictions.\n",
    "Extract the models from parent graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 : train_input_img\n",
      "layer 1 : vision\n",
      "layer 2 : train_input_idx\n",
      "layer 3 : counter\n",
      "layer 4 : detector\n"
     ]
    }
   ],
   "source": [
    "model_yaml = open('../checkpoints/model.yaml','r')\n",
    "model = keras.models.model_from_yaml(model_yaml.read())\n",
    "model_yaml.close()\n",
    "model.load_weights('../checkpoints/model.hdf5')\n",
    "\n",
    "# enumerate the layers of main graph\n",
    "for i,layer in zip(range(len(model.layers)), model.layers):\n",
    "    print \"layer {} : {}\".format(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the individual models from training graph\n",
    "vision = model.layers[1]\n",
    "counter = model.layers[3]\n",
    "detector = model.layers[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "For prediction, we will first generate the intermediate output h, from vision model. We will then pass it to counter first. Then the detector will be called for each sample with all indices in one go. \n",
    "\n",
    "The crucial part here is that we want to calculate the intermediate output h only once to save on computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = vision.predict(Ximg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ycount_ = counter.predict(h)\n",
    "ycount_ = np.argmax(ycount_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ylabel_ = []\n",
    "for i in range(len(ycount_)):\n",
    "    # generate range for each count\n",
    "    indices = np.arange(ycount_[i])\n",
    "    # one hot encoding for each index\n",
    "    indices = np_utils.to_categorical(indices, max_digits)\n",
    "    # tile h to match shape of indices matrix\n",
    "    hs = np.tile(h[i], (ycount_[i],1))\n",
    "    \n",
    "    # predict labels for the sample\n",
    "    sample_seq = detector.predict([hs, indices])\n",
    "    sample_seq = np.argmax(sample_seq,1)\n",
    "    ylabel_.append(sample_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We can evaluate the performance of both counter and label detector to get a better insight on the fit. In the end, we will evaluate the performance of the whole system. We will consider a predicted sequence to be correct only if all labels have been identified successfully, as any wrong classification can result in a totally different house number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.47      0.61      2483\n",
      "          2       0.81      0.80      0.80      8356\n",
      "          3       0.45      0.71      0.55      2081\n",
      "          4       0.26      0.43      0.32       146\n",
      "          5       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.76      0.72      0.72     13068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(ycount, ycount_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector Metrics\n",
    "Here we need to presume that counter has made a perfect prediction. If the counter itself has predicted wrong count, then it shouldn't be counted as detector's failure. So we'll evaluate the detector's performance for digits in a sequence till an index such that index is the minimum of true count value and predicted count value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ycmin = np.minimum(ycount, ycount_)\n",
    "\n",
    "# extract labels from ylabel and ylabel_ using ycmin\n",
    "ylabel_det = np.array([ylabelrow[0:ycminc] for ylabelrow,ycminc in zip(ylabel, ycmin)])\n",
    "ylabel_det = np.concatenate(ylabel_det)\n",
    "\n",
    "ylabel_det_= np.array([ylabelrow[0:ycminc] for ylabelrow,ycminc in zip(ylabel_, ycmin)])\n",
    "ylabel_det_= np.concatenate(ylabel_det_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.50      0.52      1631\n",
      "          1       0.54      0.72      0.62      4988\n",
      "          2       0.58      0.58      0.58      4060\n",
      "          3       0.48      0.41      0.44      2809\n",
      "          4       0.50      0.51      0.50      2452\n",
      "          5       0.50      0.50      0.50      2285\n",
      "          6       0.50      0.37      0.42      1911\n",
      "          7       0.55      0.51      0.53      1933\n",
      "          8       0.48      0.30      0.37      1597\n",
      "          9       0.40      0.45      0.43      1533\n",
      "\n",
      "avg / total       0.52      0.52      0.52     25199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(ylabel_det, ylabel_det_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Sequence Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence prediction accuracy : 0.326522803796\n"
     ]
    }
   ],
   "source": [
    "def matchSequence(seq, seq_):\n",
    "    return [np.array_equal(seqi, seqi_) for seqi, seqi_ in zip(seq, seq_)]\n",
    "seqmatch = matchSequence(ylabel, ylabel_)\n",
    "print \"Sequence prediction accuracy : {}\".format(np.average(seqmatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display samples\n",
    "Show some prediction results. The value in brackets is the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graphics.displaySamples(Ximg, ycounttrue=ycount, ycountpred=ycount_, ylabels=ylabel, ylabelspred=ylabel_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Convolutions\n",
    "We can visualize the convolutions in vision model to see how the image is being processed. Change **convlayer** to see the convolutions generated by the desired layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convlayer = 1\n",
    "graphics.showCNNConv(vision, convlayer, Ximg[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
